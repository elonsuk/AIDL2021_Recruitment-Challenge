{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f642bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6db4508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c46cb3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34068d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aba036",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7696fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('CSV_Files/organized_twitch_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "774d6e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Watch time(Minutes)</th>\n",
       "      <th>Stream time(minutes)</th>\n",
       "      <th>Peak viewers</th>\n",
       "      <th>Average viewers</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Followers gained</th>\n",
       "      <th>Views gained</th>\n",
       "      <th>partnered_true</th>\n",
       "      <th>mature_true</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>...</th>\n",
       "      <th>Korean</th>\n",
       "      <th>Other</th>\n",
       "      <th>Polish</th>\n",
       "      <th>Portuguese</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Slovak</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Swedish</th>\n",
       "      <th>Thai</th>\n",
       "      <th>Turkish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6196161750</td>\n",
       "      <td>215250</td>\n",
       "      <td>222720</td>\n",
       "      <td>27716</td>\n",
       "      <td>3246298</td>\n",
       "      <td>1734810</td>\n",
       "      <td>93036735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6091677300</td>\n",
       "      <td>211845</td>\n",
       "      <td>310998</td>\n",
       "      <td>25610</td>\n",
       "      <td>5310163</td>\n",
       "      <td>1370184</td>\n",
       "      <td>89705964</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5644590915</td>\n",
       "      <td>515280</td>\n",
       "      <td>387315</td>\n",
       "      <td>10976</td>\n",
       "      <td>1767635</td>\n",
       "      <td>1023779</td>\n",
       "      <td>102611607</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3970318140</td>\n",
       "      <td>517740</td>\n",
       "      <td>300575</td>\n",
       "      <td>7714</td>\n",
       "      <td>3944850</td>\n",
       "      <td>703986</td>\n",
       "      <td>106546942</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3671000070</td>\n",
       "      <td>123660</td>\n",
       "      <td>285644</td>\n",
       "      <td>29602</td>\n",
       "      <td>8938903</td>\n",
       "      <td>2068424</td>\n",
       "      <td>78998587</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Watch time(Minutes)  Stream time(minutes)  Peak viewers  Average viewers  \\\n",
       "0           6196161750                215250        222720            27716   \n",
       "1           6091677300                211845        310998            25610   \n",
       "2           5644590915                515280        387315            10976   \n",
       "3           3970318140                517740        300575             7714   \n",
       "4           3671000070                123660        285644            29602   \n",
       "\n",
       "   Followers  Followers gained  Views gained  partnered_true  mature_true  \\\n",
       "0    3246298           1734810      93036735               1            0   \n",
       "1    5310163           1370184      89705964               1            0   \n",
       "2    1767635           1023779     102611607               1            1   \n",
       "3    3944850            703986     106546942               1            0   \n",
       "4    8938903           2068424      78998587               1            0   \n",
       "\n",
       "   Chinese  ...  Korean  Other  Polish  Portuguese  Russian  Slovak  Spanish  \\\n",
       "0        0  ...       0      0       0           0        0       0        0   \n",
       "1        0  ...       0      0       0           0        0       0        0   \n",
       "2        0  ...       0      0       0           1        0       0        0   \n",
       "3        0  ...       0      0       0           0        0       0        0   \n",
       "4        0  ...       0      0       0           0        0       0        0   \n",
       "\n",
       "   Swedish  Thai  Turkish  \n",
       "0        0     0        0  \n",
       "1        0     0        0  \n",
       "2        0     0        0  \n",
       "3        0     0        0  \n",
       "4        0     0        0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94af056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hc = data.drop('Stream time(minutes)', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b367d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Watch time(Minutes)</th>\n",
       "      <th>Peak viewers</th>\n",
       "      <th>Average viewers</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Followers gained</th>\n",
       "      <th>Views gained</th>\n",
       "      <th>partnered_true</th>\n",
       "      <th>mature_true</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>Czech</th>\n",
       "      <th>...</th>\n",
       "      <th>Korean</th>\n",
       "      <th>Other</th>\n",
       "      <th>Polish</th>\n",
       "      <th>Portuguese</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Slovak</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Swedish</th>\n",
       "      <th>Thai</th>\n",
       "      <th>Turkish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6196161750</td>\n",
       "      <td>222720</td>\n",
       "      <td>27716</td>\n",
       "      <td>3246298</td>\n",
       "      <td>1734810</td>\n",
       "      <td>93036735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6091677300</td>\n",
       "      <td>310998</td>\n",
       "      <td>25610</td>\n",
       "      <td>5310163</td>\n",
       "      <td>1370184</td>\n",
       "      <td>89705964</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5644590915</td>\n",
       "      <td>387315</td>\n",
       "      <td>10976</td>\n",
       "      <td>1767635</td>\n",
       "      <td>1023779</td>\n",
       "      <td>102611607</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3970318140</td>\n",
       "      <td>300575</td>\n",
       "      <td>7714</td>\n",
       "      <td>3944850</td>\n",
       "      <td>703986</td>\n",
       "      <td>106546942</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3671000070</td>\n",
       "      <td>285644</td>\n",
       "      <td>29602</td>\n",
       "      <td>8938903</td>\n",
       "      <td>2068424</td>\n",
       "      <td>78998587</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Watch time(Minutes)  Peak viewers  Average viewers  Followers  \\\n",
       "0           6196161750        222720            27716    3246298   \n",
       "1           6091677300        310998            25610    5310163   \n",
       "2           5644590915        387315            10976    1767635   \n",
       "3           3970318140        300575             7714    3944850   \n",
       "4           3671000070        285644            29602    8938903   \n",
       "\n",
       "   Followers gained  Views gained  partnered_true  mature_true  Chinese  \\\n",
       "0           1734810      93036735               1            0        0   \n",
       "1           1370184      89705964               1            0        0   \n",
       "2           1023779     102611607               1            1        0   \n",
       "3            703986     106546942               1            0        0   \n",
       "4           2068424      78998587               1            0        0   \n",
       "\n",
       "   Czech  ...  Korean  Other  Polish  Portuguese  Russian  Slovak  Spanish  \\\n",
       "0      0  ...       0      0       0           0        0       0        0   \n",
       "1      0  ...       0      0       0           0        0       0        0   \n",
       "2      0  ...       0      0       0           1        0       0        0   \n",
       "3      0  ...       0      0       0           0        0       0        0   \n",
       "4      0  ...       0      0       0           0        0       0        0   \n",
       "\n",
       "   Swedish  Thai  Turkish  \n",
       "0        0     0        0  \n",
       "1        0     0        0  \n",
       "2        0     0        0  \n",
       "3        0     0        0  \n",
       "4        0     0        0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ab0d1b",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6e5df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d8ce093",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_hc.drop('Followers gained', axis=1).values\n",
    "y = data_hc['Followers gained'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48f46208",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d826ee",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "813f0807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9605c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51001e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b587eea1",
   "metadata": {},
   "source": [
    "### Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cc8894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import keras.backend as K\n",
    "from keras.losses import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0eae61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# FIRST DENSE LAYER\n",
    "model.add(Dense(512, activation='relu', kernel_initializer=keras.initializers.RandomUniform()))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# SECOND DENSE LAYER\n",
    "model.add(Dense(512, activation='relu', kernel_initializer=keras.initializers.RandomUniform()))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# THIRD DENSE LAYER\n",
    "model.add(Dense(256, activation='relu', kernel_initializer=keras.initializers.RandomUniform()))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# FOURTH DENSE LAYER\n",
    "model.add(Dense(256, activation='relu', kernel_initializer=keras.initializers.RandomUniform()))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# FIFTH DENSE LAYER\n",
    "model.add(Dense(128, activation='relu', kernel_initializer=keras.initializers.RandomUniform()))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# SIXTH DENSE LAYER\n",
    "model.add(Dense(128, activation='relu', kernel_initializer=keras.initializers.RandomUniform()))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# SEVENTH DENSE LAYER\n",
    "model.add(Dense(64, activation='relu', kernel_initializer=keras.initializers.RandomUniform()))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# EIGHTH DENSE LAYER\n",
    "model.add(Dense(64, activation='relu', kernel_initializer=keras.initializers.RandomUniform()))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# OUTPUT LAYER\n",
    "model.add(Dense(1))\n",
    "\n",
    "# COMPILE MODEL\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(mse(y_true, y_pred))\n",
    "\n",
    "model.compile(optimizer='adam', loss=rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f42a41",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5194a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "22/22 [==============================] - 2s 16ms/step - loss: 214928.3125 - val_loss: 183688.4688\n",
      "Epoch 2/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 200773.6875 - val_loss: 140222.3125\n",
      "Epoch 3/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 165468.0625 - val_loss: 130602.1328\n",
      "Epoch 4/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 153985.2500 - val_loss: 121399.5312\n",
      "Epoch 5/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 145615.2656 - val_loss: 113501.1172\n",
      "Epoch 6/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 136704.2812 - val_loss: 109475.5547\n",
      "Epoch 7/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 131607.1250 - val_loss: 109079.7031\n",
      "Epoch 8/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 130017.3047 - val_loss: 110839.3203\n",
      "Epoch 9/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 127742.6953 - val_loss: 108410.6562\n",
      "Epoch 10/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 128839.2422 - val_loss: 108246.8047\n",
      "Epoch 11/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 120827.7578 - val_loss: 109405.7109\n",
      "Epoch 12/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 126952.5938 - val_loss: 107100.4531\n",
      "Epoch 13/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 124119.0625 - val_loss: 106564.3828\n",
      "Epoch 14/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 120109.1562 - val_loss: 106362.8984\n",
      "Epoch 15/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 124730.7969 - val_loss: 105220.8984\n",
      "Epoch 16/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 117555.0156 - val_loss: 108730.5000\n",
      "Epoch 17/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 118521.6797 - val_loss: 110083.2656\n",
      "Epoch 18/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 116979.0391 - val_loss: 105750.3828\n",
      "Epoch 19/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 118965.8750 - val_loss: 107588.3906\n",
      "Epoch 20/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 114937.7500 - val_loss: 105056.8984\n",
      "Epoch 21/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 120732.7188 - val_loss: 104602.7578\n",
      "Epoch 22/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 118417.7344 - val_loss: 103724.9766\n",
      "Epoch 23/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 119123.8750 - val_loss: 103502.1406\n",
      "Epoch 24/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 111809.3906 - val_loss: 107212.8594\n",
      "Epoch 25/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 113696.3906 - val_loss: 107908.8516\n",
      "Epoch 26/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 113611.3359 - val_loss: 104514.3203\n",
      "Epoch 27/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 112529.5781 - val_loss: 102360.2031\n",
      "Epoch 28/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 118690.2188 - val_loss: 105976.7891\n",
      "Epoch 29/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 112663.2109 - val_loss: 107960.1797\n",
      "Epoch 30/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 120207.6484 - val_loss: 103310.6953\n",
      "Epoch 31/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 116431.1797 - val_loss: 104950.5078\n",
      "Epoch 32/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 112072.0938 - val_loss: 105814.4531\n",
      "Epoch 33/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 111509.4609 - val_loss: 104167.6406\n",
      "Epoch 34/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 111419.9297 - val_loss: 103462.2734\n",
      "Epoch 35/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 115322.2422 - val_loss: 108045.4688\n",
      "Epoch 36/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 116746.3672 - val_loss: 104600.0547\n",
      "Epoch 37/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 115968.9375 - val_loss: 102381.7891\n",
      "Epoch 38/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 113692.5938 - val_loss: 117361.1172\n",
      "Epoch 39/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 117589.7578 - val_loss: 103680.1953\n",
      "Epoch 40/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 113976.0547 - val_loss: 101886.4922\n",
      "Epoch 41/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 115500.3984 - val_loss: 101789.3438\n",
      "Epoch 42/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 113858.4141 - val_loss: 102340.3672\n",
      "Epoch 43/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 107930.4688 - val_loss: 101826.2891\n",
      "Epoch 44/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 110787.5000 - val_loss: 105193.0781\n",
      "Epoch 45/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 114849.4844 - val_loss: 104032.8047\n",
      "Epoch 46/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 112871.4062 - val_loss: 101752.9141\n",
      "Epoch 47/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 114697.0547 - val_loss: 102910.4141\n",
      "Epoch 48/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 110637.7812 - val_loss: 102878.4766\n",
      "Epoch 49/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 110110.8359 - val_loss: 102710.5547\n",
      "Epoch 50/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 111877.1875 - val_loss: 103392.5156\n",
      "Epoch 51/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 108236.0547 - val_loss: 102699.2734\n",
      "Epoch 52/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 109152.0469 - val_loss: 101885.7188\n",
      "Epoch 53/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 112129.3516 - val_loss: 102980.0391\n",
      "Epoch 54/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 112181.6562 - val_loss: 103584.4844\n",
      "Epoch 55/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 110084.5625 - val_loss: 108087.7656\n",
      "Epoch 56/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106377.5312 - val_loss: 102208.2500\n",
      "Epoch 57/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 111502.9844 - val_loss: 103343.3438\n",
      "Epoch 58/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 112895.2266 - val_loss: 103578.0312\n",
      "Epoch 59/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 104534.2422 - val_loss: 103102.6484\n",
      "Epoch 60/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 112716.7734 - val_loss: 102268.1250\n",
      "Epoch 61/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 110244.7969 - val_loss: 102918.8516\n",
      "Epoch 62/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108550.0234 - val_loss: 104193.3906\n",
      "Epoch 63/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 108635.2422 - val_loss: 105491.0234\n",
      "Epoch 64/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106757.4375 - val_loss: 102105.6875\n",
      "Epoch 65/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 104135.5781 - val_loss: 105520.9375\n",
      "Epoch 66/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 116961.7266 - val_loss: 102279.6328\n",
      "Epoch 67/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 104237.0938 - val_loss: 105287.7734\n",
      "Epoch 68/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106902.4766 - val_loss: 100593.1094\n",
      "Epoch 69/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 109115.2422 - val_loss: 100861.0156\n",
      "Epoch 70/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106933.5000 - val_loss: 104293.8828\n",
      "Epoch 71/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108618.8906 - val_loss: 101547.4766\n",
      "Epoch 72/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 109229.6562 - val_loss: 100892.6719\n",
      "Epoch 73/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108746.4922 - val_loss: 105433.8750\n",
      "Epoch 74/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 111249.4375 - val_loss: 106165.3594\n",
      "Epoch 75/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 108473.7344 - val_loss: 104649.3672\n",
      "Epoch 76/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 102779.2266 - val_loss: 104756.9141\n",
      "Epoch 77/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 112042.4688 - val_loss: 102035.3281\n",
      "Epoch 78/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 109672.6641 - val_loss: 104248.4766\n",
      "Epoch 79/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 111222.7578 - val_loss: 101059.1641\n",
      "Epoch 80/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106154.0938 - val_loss: 100867.3750\n",
      "Epoch 81/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 102580.9375 - val_loss: 103052.5234\n",
      "Epoch 82/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108883.2422 - val_loss: 103414.7578\n",
      "Epoch 83/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 110131.5234 - val_loss: 103558.0547\n",
      "Epoch 84/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 114784.0000 - val_loss: 101921.3047\n",
      "Epoch 85/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 109822.8125 - val_loss: 101867.6172\n",
      "Epoch 86/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108129.0156 - val_loss: 104693.6172\n",
      "Epoch 87/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108863.3125 - val_loss: 100050.9297\n",
      "Epoch 88/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106408.8359 - val_loss: 99942.1641\n",
      "Epoch 89/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 107413.3516 - val_loss: 101293.3359\n",
      "Epoch 90/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 116798.8594 - val_loss: 100215.1719\n",
      "Epoch 91/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 111422.8359 - val_loss: 103424.2969\n",
      "Epoch 92/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 109076.6641 - val_loss: 108926.2188\n",
      "Epoch 93/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108288.1406 - val_loss: 100255.4766\n",
      "Epoch 94/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 105964.8672 - val_loss: 106714.9531\n",
      "Epoch 95/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 112121.4609 - val_loss: 105597.0312\n",
      "Epoch 96/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 111062.5859 - val_loss: 100633.9375\n",
      "Epoch 97/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 109539.3750 - val_loss: 102799.7969\n",
      "Epoch 98/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 112143.1328 - val_loss: 100832.9688\n",
      "Epoch 99/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 105101.8984 - val_loss: 101442.4375\n",
      "Epoch 100/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 108328.6250 - val_loss: 100019.7578\n",
      "Epoch 101/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106448.1406 - val_loss: 101168.9531\n",
      "Epoch 102/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 114374.4688 - val_loss: 99544.0391\n",
      "Epoch 103/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 111319.6016 - val_loss: 99084.8281\n",
      "Epoch 104/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 107695.2578 - val_loss: 102592.2500\n",
      "Epoch 105/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 110124.3906 - val_loss: 100476.2578\n",
      "Epoch 106/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 111151.6953 - val_loss: 99600.3828\n",
      "Epoch 107/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 109220.5156 - val_loss: 101237.7656\n",
      "Epoch 108/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 110733.0547 - val_loss: 103497.9297\n",
      "Epoch 109/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 111891.3281 - val_loss: 101222.6562\n",
      "Epoch 110/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108491.2578 - val_loss: 101583.8359\n",
      "Epoch 111/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106544.3906 - val_loss: 99770.1484\n",
      "Epoch 112/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 108473.9297 - val_loss: 102068.2734\n",
      "Epoch 113/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 105689.5859 - val_loss: 100500.4531\n",
      "Epoch 114/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108174.0703 - val_loss: 100275.8516\n",
      "Epoch 115/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106560.8203 - val_loss: 100233.4062\n",
      "Epoch 116/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 109406.6641 - val_loss: 102938.9609\n",
      "Epoch 117/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 103933.9531 - val_loss: 100097.4062\n",
      "Epoch 118/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 114916.2891 - val_loss: 102974.2812\n",
      "Epoch 119/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 105854.5391 - val_loss: 101000.8984\n",
      "Epoch 120/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 107073.3750 - val_loss: 100503.0781\n",
      "Epoch 121/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 105154.0078 - val_loss: 103799.1172\n",
      "Epoch 122/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 109346.0703 - val_loss: 107443.3594\n",
      "Epoch 123/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 110535.6094 - val_loss: 100035.3203\n",
      "Epoch 124/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106419.8203 - val_loss: 100484.1875\n",
      "Epoch 125/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108463.5234 - val_loss: 101024.4219\n",
      "Epoch 126/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 104153.2266 - val_loss: 100483.7188\n",
      "Epoch 127/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 107850.8359 - val_loss: 99344.6719\n",
      "Epoch 128/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 112082.0000 - val_loss: 100217.4375\n",
      "Epoch 129/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108900.0547 - val_loss: 101579.9844\n",
      "Epoch 130/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106498.3203 - val_loss: 99812.9219\n",
      "Epoch 131/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 104072.8594 - val_loss: 99550.3203\n",
      "Epoch 132/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 105068.0938 - val_loss: 100114.6094\n",
      "Epoch 133/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 104786.5859 - val_loss: 99728.5156\n",
      "Epoch 134/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 109744.1562 - val_loss: 99382.8828\n",
      "Epoch 135/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 109395.9766 - val_loss: 100837.3594\n",
      "Epoch 136/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108393.9922 - val_loss: 101531.9453\n",
      "Epoch 137/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 112199.8984 - val_loss: 99363.7031\n",
      "Epoch 138/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 110361.7500 - val_loss: 98953.5703\n",
      "Epoch 139/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 104618.7578 - val_loss: 99468.8047\n",
      "Epoch 140/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 99812.1719 - val_loss: 106503.4609\n",
      "Epoch 141/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 104541.7500 - val_loss: 102542.7188\n",
      "Epoch 142/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 107071.3281 - val_loss: 103526.0703\n",
      "Epoch 143/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108814.7344 - val_loss: 106387.2969\n",
      "Epoch 144/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 107365.3359 - val_loss: 100763.9062\n",
      "Epoch 145/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 109670.9844 - val_loss: 100357.7188\n",
      "Epoch 146/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 103641.8047 - val_loss: 105454.7578\n",
      "Epoch 147/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 103175.6328 - val_loss: 106144.1562\n",
      "Epoch 148/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 101512.5469 - val_loss: 102006.7734\n",
      "Epoch 149/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 8ms/step - loss: 113004.5703 - val_loss: 100776.2422\n",
      "Epoch 150/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 110005.1172 - val_loss: 100980.7031\n",
      "Epoch 151/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 112204.7656 - val_loss: 100351.0938\n",
      "Epoch 152/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 103283.0547 - val_loss: 100021.1250\n",
      "Epoch 153/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 102830.3281 - val_loss: 100077.2578\n",
      "Epoch 154/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106212.6719 - val_loss: 100549.6406\n",
      "Epoch 155/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106829.7969 - val_loss: 99749.1562\n",
      "Epoch 156/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 112769.8984 - val_loss: 101980.4141\n",
      "Epoch 157/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 105981.1562 - val_loss: 100371.7578\n",
      "Epoch 158/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 103931.6797 - val_loss: 100273.2812\n",
      "Epoch 159/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 109554.1016 - val_loss: 99995.3828\n",
      "Epoch 160/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108989.2109 - val_loss: 100804.2109\n",
      "Epoch 161/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 104461.9531 - val_loss: 105142.4375\n",
      "Epoch 162/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 102965.2578 - val_loss: 101133.4688\n",
      "Epoch 163/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 103561.1875 - val_loss: 101584.3125\n",
      "Epoch 164/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 110260.3281 - val_loss: 101812.4375\n",
      "Epoch 165/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108450.4375 - val_loss: 102692.1250\n",
      "Epoch 166/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 107576.2891 - val_loss: 101136.5703\n",
      "Epoch 167/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 98299.6328 - val_loss: 99515.4375\n",
      "Epoch 168/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106083.7578 - val_loss: 99995.8125\n",
      "Epoch 169/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106814.0312 - val_loss: 98299.4766\n",
      "Epoch 170/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106661.8828 - val_loss: 102984.5859\n",
      "Epoch 171/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 108207.0391 - val_loss: 101431.0156\n",
      "Epoch 172/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 105288.5391 - val_loss: 101982.5547\n",
      "Epoch 173/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 107564.0312 - val_loss: 101824.4297\n",
      "Epoch 174/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 102979.7969 - val_loss: 99045.4375\n",
      "Epoch 175/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 102436.6172 - val_loss: 101374.1797\n",
      "Epoch 176/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 111102.4219 - val_loss: 100641.1406\n",
      "Epoch 177/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108380.9219 - val_loss: 98684.1250\n",
      "Epoch 178/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106481.8516 - val_loss: 99607.1172\n",
      "Epoch 179/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108969.3125 - val_loss: 100397.3906\n",
      "Epoch 180/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 105602.8438 - val_loss: 99254.6406\n",
      "Epoch 181/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 104779.2266 - val_loss: 99237.9922\n",
      "Epoch 182/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 104948.0547 - val_loss: 103328.5703\n",
      "Epoch 183/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 109591.3047 - val_loss: 98966.0000\n",
      "Epoch 184/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108592.9375 - val_loss: 102322.7969\n",
      "Epoch 185/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106021.7031 - val_loss: 100136.9922\n",
      "Epoch 186/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 101152.5469 - val_loss: 100953.6250\n",
      "Epoch 187/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 105559.4766 - val_loss: 99639.1328\n",
      "Epoch 188/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 105901.1094 - val_loss: 99347.5938\n",
      "Epoch 189/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 109443.6016 - val_loss: 99841.7344\n",
      "Epoch 190/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 101648.3047 - val_loss: 99468.9922\n",
      "Epoch 191/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 103296.0703 - val_loss: 103503.2656\n",
      "Epoch 192/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 109307.6016 - val_loss: 99062.2266\n",
      "Epoch 193/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 113732.8828 - val_loss: 99775.8125\n",
      "Epoch 194/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 102927.3594 - val_loss: 104357.3984\n",
      "Epoch 195/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 104613.2109 - val_loss: 100917.4922\n",
      "Epoch 196/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 105936.5234 - val_loss: 101865.9375\n",
      "Epoch 197/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 105651.0391 - val_loss: 98996.4297\n",
      "Epoch 198/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 105610.3047 - val_loss: 100368.6484\n",
      "Epoch 199/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 109894.2266 - val_loss: 104261.1172\n",
      "Epoch 200/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108690.0078 - val_loss: 102191.8984\n",
      "Epoch 201/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 105800.7344 - val_loss: 101277.8984\n",
      "Epoch 202/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 112652.5859 - val_loss: 99894.7969\n",
      "Epoch 203/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 112660.9688 - val_loss: 98776.6641\n",
      "Epoch 204/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 102899.5781 - val_loss: 100218.1250\n",
      "Epoch 205/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 108077.7266 - val_loss: 100868.3828\n",
      "Epoch 206/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 106156.5469 - val_loss: 102359.2578\n",
      "Epoch 207/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 103302.6484 - val_loss: 102779.9766\n",
      "Epoch 208/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 108224.6719 - val_loss: 99843.7500\n",
      "Epoch 209/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 107840.9141 - val_loss: 98734.2578\n",
      "Epoch 210/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 105552.5469 - val_loss: 99462.5078\n",
      "Epoch 211/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108486.6094 - val_loss: 99469.0781\n",
      "Epoch 212/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106804.8828 - val_loss: 101713.0703\n",
      "Epoch 213/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 104700.1484 - val_loss: 101181.6094\n",
      "Epoch 214/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 107523.0859 - val_loss: 98924.5703\n",
      "Epoch 215/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 106217.5859 - val_loss: 100835.9688\n",
      "Epoch 216/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 101713.2031 - val_loss: 99407.1641\n",
      "Epoch 217/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 107235.7734 - val_loss: 102320.1484\n",
      "Epoch 218/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 99323.8281 - val_loss: 101400.4453\n",
      "Epoch 219/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 103921.4844 - val_loss: 102080.9922\n",
      "Epoch 220/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 104132.3281 - val_loss: 100622.9297\n",
      "Epoch 221/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 104604.0000 - val_loss: 99970.0234\n",
      "Epoch 222/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 104277.9766 - val_loss: 100000.9297\n",
      "Epoch 223/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 100777.1562 - val_loss: 102185.8125\n",
      "Epoch 224/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 113849.3047 - val_loss: 102208.7031\n",
      "Epoch 225/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 106629.0859 - val_loss: 99444.5234\n",
      "Epoch 226/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 103384.5469 - val_loss: 99743.6328\n",
      "Epoch 227/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 102184.7344 - val_loss: 99585.8516\n",
      "Epoch 228/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 102215.0859 - val_loss: 99598.1875\n",
      "Epoch 229/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 108721.0625 - val_loss: 103331.4688\n",
      "Epoch 230/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 104984.7578 - val_loss: 100869.4844\n",
      "Epoch 231/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 104644.0000 - val_loss: 101689.6562\n",
      "Epoch 232/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 110076.5234 - val_loss: 99845.9531\n",
      "Epoch 233/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 107603.2266 - val_loss: 101000.0312\n",
      "Epoch 234/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 105398.3516 - val_loss: 98677.1172\n",
      "Epoch 235/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 109496.9844 - val_loss: 98531.9531\n",
      "Epoch 236/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106686.3203 - val_loss: 99137.3359\n",
      "Epoch 237/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 107752.9688 - val_loss: 99335.8438\n",
      "Epoch 238/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 107360.1562 - val_loss: 108091.7969\n",
      "Epoch 239/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 110050.7891 - val_loss: 101292.2109\n",
      "Epoch 240/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106872.0469 - val_loss: 100987.6094\n",
      "Epoch 241/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 109474.1484 - val_loss: 97492.2344\n",
      "Epoch 242/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 105220.0781 - val_loss: 99470.3281\n",
      "Epoch 243/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 110973.5000 - val_loss: 99404.6953\n",
      "Epoch 244/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 108502.4453 - val_loss: 100246.1875\n",
      "Epoch 245/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 105551.2656 - val_loss: 99227.7656\n",
      "Epoch 246/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 104544.2266 - val_loss: 99282.9375\n",
      "Epoch 247/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 104153.7969 - val_loss: 99968.3984\n",
      "Epoch 248/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 108414.5703 - val_loss: 104746.3984\n",
      "Epoch 249/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 109927.8516 - val_loss: 99344.8906\n",
      "Epoch 250/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 109326.7734 - val_loss: 99900.3672\n",
      "Epoch 251/300\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 106708.9375 - val_loss: 101080.1719\n",
      "Epoch 252/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 107304.8672 - val_loss: 101375.6172\n",
      "Epoch 253/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 103669.5781 - val_loss: 98839.5781\n",
      "Epoch 254/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 109552.9375 - val_loss: 99500.1641\n",
      "Epoch 255/300\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 102002.4766 - val_loss: 100760.7969\n",
      "Epoch 256/300\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 100361.8203 - val_loss: 102106.8594\n",
      "Epoch 257/300\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 112124.3672 - val_loss: 104315.8594\n",
      "Epoch 258/300\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 109677.9062 - val_loss: 99499.7344\n",
      "Epoch 259/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 100812.4141 - val_loss: 104068.2656\n",
      "Epoch 260/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 106830.4453 - val_loss: 98801.2422\n",
      "Epoch 261/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 105346.4688 - val_loss: 99101.5391\n",
      "Epoch 262/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 106118.0000 - val_loss: 98217.6562\n",
      "Epoch 263/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 102199.9062 - val_loss: 99842.9141\n",
      "Epoch 264/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 105828.7422 - val_loss: 99132.6016\n",
      "Epoch 265/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 104009.4609 - val_loss: 98809.0625\n",
      "Epoch 266/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 104405.4297 - val_loss: 101283.4922\n",
      "Epoch 267/300\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 106524.0000 - val_loss: 98594.8359\n",
      "Epoch 268/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 107050.8672 - val_loss: 98571.9609\n",
      "Epoch 269/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 109069.6719 - val_loss: 97643.4766\n",
      "Epoch 270/300\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 101531.3125 - val_loss: 97860.4766\n",
      "Epoch 271/300\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 107004.7422 - val_loss: 98450.8828\n",
      "Epoch 272/300\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 111470.0312 - val_loss: 98493.7031\n",
      "Epoch 273/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 104841.1875 - val_loss: 103122.1953\n",
      "Epoch 274/300\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 102262.2656 - val_loss: 99604.7500\n",
      "Epoch 275/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 113750.7656 - val_loss: 98150.7891\n",
      "Epoch 276/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 107144.7891 - val_loss: 100521.2500\n",
      "Epoch 277/300\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 105889.2656 - val_loss: 101670.1953\n",
      "Epoch 278/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 104752.1484 - val_loss: 99593.9219\n",
      "Epoch 279/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 103612.0312 - val_loss: 99062.4453\n",
      "Epoch 280/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 105656.9219 - val_loss: 104171.9922\n",
      "Epoch 281/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 108788.9219 - val_loss: 98986.2109\n",
      "Epoch 282/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 101192.7891 - val_loss: 98658.8828\n",
      "Epoch 283/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 100673.7266 - val_loss: 103429.7031\n",
      "Epoch 284/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 106970.0781 - val_loss: 99015.8281\n",
      "Epoch 285/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 103483.0859 - val_loss: 100510.8828\n",
      "Epoch 286/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 104500.1719 - val_loss: 99610.0703\n",
      "Epoch 287/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 107964.9453 - val_loss: 99153.8906\n",
      "Epoch 288/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 108367.0859 - val_loss: 100967.7266\n",
      "Epoch 289/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 109794.6953 - val_loss: 98577.1953\n",
      "Epoch 290/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 108331.1406 - val_loss: 99377.6875\n",
      "Epoch 291/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 103964.5469 - val_loss: 98316.1094\n",
      "Epoch 292/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 102213.0859 - val_loss: 98625.4453\n",
      "Epoch 293/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 100765.5859 - val_loss: 99292.4453\n",
      "Epoch 294/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 106709.7031 - val_loss: 109834.5625\n",
      "Epoch 295/300\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 109228.8125 - val_loss: 98500.0078\n",
      "Epoch 296/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 104514.8828 - val_loss: 101725.1172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 105139.7734 - val_loss: 97789.2578\n",
      "Epoch 298/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 101857.3906 - val_loss: 98762.4062\n",
      "Epoch 299/300\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 103609.5859 - val_loss: 98122.5547\n",
      "Epoch 300/300\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 101807.6484 - val_loss: 100476.8516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23b1a0f2460>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_test, y_test), batch_size=32, epochs=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec4071",
   "metadata": {},
   "source": [
    "### Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9025c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda98438",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01791dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d61f06e",
   "metadata": {},
   "source": [
    "Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17853c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40157982365.716156"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2d9816",
   "metadata": {},
   "source": [
    "Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e4c36d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200394.56670707455"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef7fd14",
   "metadata": {},
   "source": [
    "Explained Variance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "952c0587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5735885953047817"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f039a8a2",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfde2f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.190851730513906"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, predictions) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7301875c",
   "metadata": {},
   "source": [
    "Conclusion 3: Results are better than the predictions made with the model with the dataset with removed outliers. Yet, the predictions made using this model still does not exceed the original results (although, the RMSE, explained variance score, and accuracy are quite close to the original).\n",
    "<br>AND one critical feature that I missed: a negative correlation is still a correlation. Which means, it is a feature that can be used to train the model. More simply, there is no meaning for conducting this third notebook. Just ignore it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872cac0",
   "metadata": {},
   "source": [
    "I'm leaving this notebook despite its lack of meaning, as it acted as a kind reminder for me, and it is a part of my exploration.\n",
    "<br>But in general, to make a final conclusion, there are only 1000 rows in this dataset. More Twitch streamers are demanded here for the model to be capable enough in making accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1f1614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
